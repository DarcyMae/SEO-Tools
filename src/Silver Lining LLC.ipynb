{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8255a20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import anthropic\n",
    "import gradio as gr\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab98cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables.\n",
    "dotenv_path = './example.env'\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Store the API key in a variable.\n",
    "ClaudeAPI_Key = os.getenv(\"ClaudeAPI_Key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d1c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for list parser.\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c451951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "chat = ChatAnthropic(temperature=0, api_key=\"ClaudeAPI_Key\", model_name=\"claude-3-opus-20240229\")\n",
    "\n",
    "# Initialize the output parser.\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# Get the output format instructions.\n",
    "instructions = parser.get_format_instructions()\n",
    "print(instructions)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "195b25e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "Running on public URL: https://010fce607b95a0faa1.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://010fce607b95a0faa1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your pre-trained model and tokenizer here\n",
    "model = tf.keras.models.load_model('SecondRun.keras')\n",
    "\n",
    "# Load the pickled tokenizer\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "client = anthropic.Anthropic(api_key=ClaudeAPI_Key)\n",
    "\n",
    "# Our definitions:\n",
    "def analyze_and_respond(review):\n",
    "    # Tokenize and pad the input review\n",
    "    sequence = tokenizer.texts_to_sequences([review])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=50)\n",
    "    \n",
    "    # Get prediction from your model\n",
    "    lstm_prediction = model.predict(padded_sequence)[0][0]\n",
    "    lstm_sentiment = \"positive\" if lstm_prediction > 0.5 else \"negative\"\n",
    "    \n",
    "    # Create the initial message for Claude\n",
    "    initial_message = f'''You are an AI assistant tasked with analyzing and responding to Google reviews. You will be provided with a Google review. Your job is to determine the sentiment, and then craft an appropriate response based on whether the review is positive or negative.\n",
    "\n",
    "Here is the Google review you need to analyze:\n",
    "<google_review>\n",
    "{review}\n",
    "</google_review>\n",
    "\n",
    "First, carefully read the review and determine if it is positive or negative. \n",
    "\n",
    "In your analysis, consider the following:\n",
    "- The overall tone of the review\n",
    "- Any specific praise or complaints mentioned\n",
    "- The star rating, if provided\n",
    "\n",
    "Write your sentiment analysis inside <sentiment_analysis> tags. Include your reasoning and whether you think the review is positive or negative.\n",
    "\n",
    "After your analysis, proceed based on whether the review is positive or negative:\n",
    "\n",
    "For a positive review:\n",
    "1. Express gratitude for the positive feedback\n",
    "2. Highlight a specific point from the review, if applicable\n",
    "3. Keep the tone warm and appreciative\n",
    "\n",
    "For a negative review:\n",
    "1. Express regret for the unsatisfactory experience\n",
    "2. Acknowledge the specific issues mentioned in the review\n",
    "3. Craft a response that:\n",
    "   a. Addresses the concerns raised\n",
    "   b. Explains steps being taken to improve\n",
    "   c. Invites the customer to give the business another chance\n",
    "4. Keep the tone professional, empathetic, and solution-oriented\n",
    "5. Keep the response to a character limit of 500 characters.\n",
    "\n",
    "Write your final response inside <response> tags.\n",
    "\n",
    "Remember, your goal is to maintain a positive relationship with the customer, address their concerns, and uphold the reputation of the business.'''\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": initial_message}]}\n",
    "    ]\n",
    "\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # Extract the text content from the response\n",
    "    claude_analysis = response.content[0].text if isinstance(response.content, list) else response.content\n",
    "\n",
    "    # Ensure claude_analysis is a string\n",
    "    if not isinstance(claude_analysis, str):\n",
    "        claude_analysis = str(claude_analysis)\n",
    "\n",
    "    # Extract Claude's sentiment from the analysis\n",
    "    claude_sentiment = \"positive\" if \"positive\" in claude_analysis.lower() else \"negative\"\n",
    "\n",
    "    # Compare LSTM and Claude sentiments\n",
    "    agreement = \"Agree\" if lstm_sentiment == claude_sentiment else \"Disagree\"\n",
    "\n",
    "    # Extract Claude's response\n",
    "    response_match = re.search(r'<response>(.*?)</response>', claude_analysis, re.DOTALL)\n",
    "    claude_response = response_match.group(1).strip() if response_match else \"No response found.\"\n",
    "\n",
    "    # Create the final output\n",
    "    final_output = f\"Our LSTM and Claude {agreement} that this is a {claude_sentiment} review.\\n\\n{claude_response}\"\n",
    "\n",
    "    return final_output\n",
    "\n",
    "def process_review(review):\n",
    "    final_response = analyze_and_respond(review)\n",
    "    return final_response, gr.update(visible=True)\n",
    "\n",
    "#Gradio interface \n",
    "\n",
    "with gr.Blocks(theme='freddyaboulton/dracula_revamped') as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    <div style=\"display: flex; align-items: center;\">\n",
    "        <img src=\"https://www.logostack.com/wp-content/uploads/designers/ArtFreedom/12-01-4-900x600.jpg\" alt=\"Logo\" style=\"width: 50px; margin-right: 10px;\">\n",
    "        <h1>Silver Lining LLC</h1>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    review_input = gr.Textbox(label=\"Insert Google Review\")\n",
    "    analyze_button = gr.Button(\"Analyze Review\")\n",
    "    \n",
    "    final_output = gr.Textbox(label=\"Analysis and Response\")\n",
    "    \n",
    "    with gr.Group(visible=False) as approval_group:\n",
    "        approve_button = gr.Button(\"Approve Response\")\n",
    "    \n",
    "    analyze_button.click(\n",
    "        process_review,\n",
    "        inputs=[review_input],\n",
    "        outputs=[final_output, approval_group]\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a6c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
